============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
2025-04-15 23:50:24.618922: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-15 23:50:24.637005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1744753824.655273  892462 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1744753824.661682  892462 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1744753824.678804  892462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1744753824.678824  892462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1744753824.678827  892462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1744753824.678828  892462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-04-15 23:50:24.684257: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Training (step 1/100000):   0%|          | 0/350 [00:00<?, ?it/s]Training (step 1/100000):   0%|          | 0/350 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/gpfs/home5/scur2687/erwin/experiments/train_shapenet.py", line 146, in <module>
    fit(config, model, optimizer, scheduler, train_loader, valid_loader, test_loader, 110, 160)
  File "/gpfs/home5/scur2687/erwin/experiments/../../erwin/training.py", line 107, in fit
    for batch in iterator:
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/_utils.py", line 715, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/gpfs/home5/scur2687/erwin/experiments/../../erwin/experiments/datasets/shapenet.py", line 87, in __getitem__
    all_pos = self.getitem_all_pos(idx)
  File "/gpfs/home5/scur2687/erwin/experiments/../../erwin/experiments/datasets/shapenet.py", line 81, in getitem_all_pos
    all_pos = torch.load(f"{self.uris[idx]}/mesh_points.th", weights_only=True)
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/serialization.py", line 1319, in load
    with _open_file_like(f, "rb") as opened_file:
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/serialization.py", line 659, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/gpfs/home5/scur2687/erwin/erwin/lib64/python3.9/site-packages/torch/serialization.py", line 640, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '../shapenet_car/mlcfd_data/training_data/param2/7e6da78c8dde0479f30da7304391ba9f/mesh_points.th'

srun: error: gcn3: task 0: Exited with exit code 1
srun: Terminating StepId=11201300.0

JOB STATISTICS
==============
Job ID: 11201300
Cluster: snellius
User/Group: scur2687/scur2687
State: RUNNING
Nodes: 1
Cores per node: 9
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:03:00 core-walltime
Job Wall-clock time: 00:00:20
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 60.00 GB (60.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
